{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request \n",
    "### \"would like to extract the summary from Swedish text using Python program\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till we do not have an original example of a text we will be analyzing, I take a classical text by August Strinberg \"Ett halvt ark papper\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main approaches to summarizing text documents; they are:\n",
    "\n",
    " 1. Extractive Methods.\n",
    " 2. Abstractive Methods.\n",
    "\n",
    "#### \"Extractive summarization methods\n",
    "work by identifying important sections of the text and generating them verbatim.\n",
    "#### Abstractive summarization methods \n",
    "aim at producing important material in a new way. In other words, they interpret and examine the text using advanced natural language techniques in order to generate a new shorter text that conveys the most critical information from the original text.\" \n",
    "\n",
    "— Text Summarization Techniques: A Brief Survey, 2017. (https://arxiv.org/abs/1707.02268)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I choose the extractive method to pursue, because it seems to be easier to execute and more accurate in our case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Ett halvt ark papper\n",
      "0   Sista flyttningslasset hade gått; hyresgästen,...\n",
      "1   Han tog ner arket; det var sådant där sol-gult...\n",
      "2   Så kom det: Blomsterhandeln och Hyrkusken. Det...\n",
      "3   Därpå: Möbelhandlarn, Tapetserarn. Han sätter ...\n",
      "4   Operans biljettkontor: 50.50. De äro nygifta o...\n",
      "5   Här följer ett mansnamn som är överstruket. De...\n",
      "6   Här synes något nytt ha inträtt i makarnes liv...\n",
      "7                    Under hennes namn står Doktor L.\n",
      "8   För första gången dyker här upp namnet på en s...\n",
      "9   Här börjar ett stort klotter med blått och röt...\n",
      "10  Kryddbon, Slaktarn etc.! Huset börjar skötas p...\n",
      "11  Det som sedan följde kunde han icke läsa, ty d...\n",
      "12  Det talar ju nog!  En större och en mindre, u...\n",
      "13  Sedan stod där intet mer! Stoft slutade det me...\n",
      "14  Men han tog sol-papperet, kysste det och lade ...\n",
      "15  På två minuter hade han genomlevat två år av s...\n",
      "16  Han var icke böjd när han gick ut; han bar tvä...\n"
     ]
    }
   ],
   "source": [
    "#read txt with text\n",
    "data= \"ett_halvt_ark_papper.txt\"\n",
    "text_data=pd.read_csv(data,sep='|', encoding='latin-1')\n",
    "print(text_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data type\n",
    "type(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adjusting data type, converting data frame to string\n",
    "text= text_data.to_string()\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENSIM\n",
    "The gensim implementation is based on the popular “TextRank” algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-17 16:36:26,100 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-05-17 16:36:26,107 : INFO : built Dictionary(88 unique tokens: ['ark', 'ett', 'halvt', 'papper', 'flyttningslasset']...) from 24 documents (total 119 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "1   Han tog ner arket; det var sådant där sol-gult...\n",
      "9   Här börjar ett stort klotter med blått och röt...\n",
      "11  Det som sedan följde kunde han icke läsa, ty d...\n",
      "14  Men han tog sol-papperet, kysste det och lade ...\n"
     ]
    }
   ],
   "source": [
    "print ('Summary:')\n",
    "print (summarize(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
